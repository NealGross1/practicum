{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_results_df = pd.read_csv('C:/Users/neals/Desktop/practicum/prompt_results_classification.csv')\n",
    "prompt_results_df['prompt'] = prompt_results_df['prompt'].fillna('')\n",
    "prompt_results_df.prompt.unique()\n",
    "context_df = prompt_results_df[prompt_results_df['prompt']=='']\n",
    "context_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'E:/datasets'\n",
    "dataset_name = 'DOTA_dataset_512'\n",
    "coco_dir = f'{dataset_dir}/{dataset_name}'\n",
    "coco_file = f'{coco_dir}/val_coco.json'\n",
    "coco_file = f'{coco_dir}/YOLO_coco_results_annots.json'\n",
    "\n",
    "with open(coco_file, 'r') as f:\n",
    "    coco_json = json.load(f)\n",
    "\n",
    "category_map = {cat['id']:cat['name'] for cat in coco_json['categories']}\n",
    "annotation_df = pd.DataFrame(coco_json['annotations'])\n",
    "annotation_df['category'] = annotation_df['category_id'].map(category_map)\n",
    "annotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_agg = annotation_df.groupby('image_id')['category'].agg(lambda x: list(set(x))).reset_index()\n",
    "category_agg.rename(columns={'category': 'category_list'}, inplace=True)\n",
    "# Flatten the lists and find unique values\n",
    "unique_values = pd.Series([item for sublist in category_agg['category_list'] for item in sublist]).unique()\n",
    "\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = context_df.merge(category_agg, on='image_id', how='left').dropna()\n",
    "context_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ship_words = ['water','boats','dock','boat','marina','docked','ship','ocean','lake','sea']\n",
    "top_plane_words =['airport','tarmac','runway','plane','planes','airplanes','airplane','military','flying','aerial']\n",
    "\n",
    "def set_word_match_score(row, match_words):\n",
    "    sentence = row.generated_text\n",
    "    # Split the sentence into individual words\n",
    "    words_in_sentence = set(sentence.lower().split())\n",
    "    \n",
    "    # Count how many words from match_words are in the sentence\n",
    "    matched_words = sum(1 for word in match_words if word.lower() in words_in_sentence)\n",
    "    \n",
    "    # Calculate the score as matched words / total match words\n",
    "    return matched_words / len(match_words)\n",
    "\n",
    "context_df['plane_score'] = context_df.apply(lambda x: set_word_match_score(x, top_plane_words), axis=1)\n",
    "context_df['ship_score'] = context_df.apply(lambda x: set_word_match_score(x, top_ship_words), axis=1)\n",
    "context_df['has_plane'] = context_df['category_list'].apply(lambda x: 'plane' in x)\n",
    "context_df['has_ship'] = context_df['category_list'].apply(lambda x: 'ship' in x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_plane_context_df = context_df[(context_df['has_plane']==False)&(context_df['plane_score']>0.1)]\n",
    "no_plane_context_df = no_plane_context_df.sort_values(by='plane_score',ascending=False)\n",
    "no_plane_context_df.head(10)\n",
    "print(len(no_plane_context_df.index))\n",
    "for ind,  row in enumerate(no_plane_context_df.itertuples()):\n",
    "    img = Image.open(row.image_path)\n",
    "    print(row.image_path)\n",
    "    print(row.plane_score)\n",
    "    print(row.generated_text)\n",
    "    display(img)\n",
    "    if ind>5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ship_context_df = context_df[(context_df['has_ship']==False)&(context_df['ship_score']>0.1)]\n",
    "no_ship_context_df = no_ship_context_df.sort_values(by='ship_score',ascending=False)\n",
    "no_ship_context_df.head(10)\n",
    "print(len(no_ship_context_df.index))\n",
    "for ind,  row in enumerate(no_ship_context_df.itertuples()):\n",
    "    img = Image.open(row.image_path)\n",
    "    print(row.category_list)\n",
    "    print(row.image_path)\n",
    "    print(row.ship_score)\n",
    "    print(row.generated_text)\n",
    "    display(img)\n",
    "    if ind>5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ship_context_df = context_df[(context_df['has_ship']==False)&(context_df['ship_score']>0.1)\n",
    "                                &(~context_df['generated_text'].str.contains('dock'))\n",
    "                                &(~context_df['generated_text'].str.contains('houses'))]\n",
    "no_ship_context_df = no_ship_context_df.sort_values(by='ship_score',ascending=False)\n",
    "no_ship_context_df.head(10)\n",
    "print(len(no_ship_context_df.index))\n",
    "for ind,  row in enumerate(no_ship_context_df.itertuples()):\n",
    "    img = Image.open(row.image_path)\n",
    "    print(row.category_list)\n",
    "    print(row.image_path)\n",
    "    print(row.ship_score)\n",
    "    print(row.generated_text)\n",
    "    display(img)\n",
    "    if ind>30: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
